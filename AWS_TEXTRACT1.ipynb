{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page_3.png...\n",
      "Processing page_4.png...\n",
      "Processing page_5.png...\n",
      "Processing page_6.png...\n",
      "Processing page_7.png...\n",
      "Processing page_8.png...\n",
      "Processing page_9.png...\n",
      "Processing page_10.png...\n",
      "Processing page_11.png...\n",
      "Processing page_12.png...\n",
      "Processing page_13.png...\n",
      "Processing page_14.png...\n",
      "Processing page_15.png...\n",
      "Processing page_16.png...\n",
      "Processing page_17.png...\n",
      "Processing page_18.png...\n",
      "Processing page_19.png...\n",
      "Processing page_20.png...\n",
      "Processing page_21.png...\n",
      "Processing page_22.png...\n",
      "Processing page_23.png...\n",
      "Processing page_24.png...\n",
      "Processing page_25.png...\n",
      "Processing page_26.png...\n",
      "Processing page_27.png...\n",
      "Processing page_28.png...\n",
      "Processing page_29.png...\n",
      "Processing page_30.png...\n",
      "Processing page_31.png...\n",
      "Processing page_32.png...\n",
      "Processing page_33.png...\n",
      "Processing page_34.png...\n",
      "Processing page_35.png...\n",
      "Processing page_36.png...\n",
      "Processing page_37.png...\n",
      "Processing page_38.png...\n",
      "Processing page_39.png...\n",
      "Processing page_40.png...\n",
      "Processing page_41.png...\n",
      "Processing page_42.png...\n",
      "Processing page_43.png...\n",
      "Processing page_44.png...\n",
      "Processing page_45.png...\n",
      "Processing page_46.png...\n",
      "Processing page_47.png...\n",
      "Processing page_48.png...\n",
      "Data successfully saved to '123 - Sanpada.csv'.\n",
      "No anomalies detected.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Initialize a dictionary to store all results across pages\n",
    "final_result = {}\n",
    "anomaly_detected = False  # Flag for detecting anomalies\n",
    "anomaly_pages = []  # List to track pages with anomalies\n",
    "global_counter = 1  # Initialize the global counter for numbering\n",
    "assembly_data = {}  # Dictionary to store unique section names by section number\n",
    "\n",
    "# Initialize boto3 Textract client (update credentials as needed)\n",
    "client = boto3.client('textract',\n",
    "                      aws_access_key_id='',\n",
    "                      aws_secret_access_key='',\n",
    "                      region_name='ap-south-1')\n",
    "\n",
    "# Initialize additional columns to store global information for each file\n",
    "assembly_constituency_no_and_name = \"\"\n",
    "part_no = \"\"\n",
    "section_type = \"\"\n",
    "section_value = \"\"\n",
    "\n",
    "def process_text_file(data, page_number):\n",
    "    global assembly_constituency_no_and_name, part_no, global_counter, assembly_data\n",
    "\n",
    "    # Initialize a list for storing results from this page\n",
    "    results = []\n",
    "    previous_line = \"\"  # To track the line above the current line\n",
    "\n",
    "    # Split the input data into lines\n",
    "    lines = data.splitlines()\n",
    "\n",
    "    # Initialize section_number and section_name with default values\n",
    "    section_number = None\n",
    "    section_name = None\n",
    "\n",
    "    # Extract \"Assembly Constituency No and Name\", \"Part No\", and \"Section No and Name\"\n",
    "    for line in lines:\n",
    "        # Extracting Assembly Constituency No and Name\n",
    "        ac_match = re.match(r'Assembly Constituency No and Name\\s*:?\\s*([\\dA-Za-z\\s-]+)', line)\n",
    "        if ac_match:\n",
    "            assembly_constituency_no_and_name = ac_match.group(1).strip() if ac_match.group(1) else \"\"\n",
    "\n",
    "        # Extracting Part No\n",
    "        part_match = re.match(r'Part No.\\s*:?\\s*(\\d+)', line)\n",
    "        if part_match:\n",
    "            part_no = part_match.group(1).strip() if part_match.group(1) else \"\"\n",
    "\n",
    "        # Extracting Section No and Name\n",
    "        section_match = re.match(r'Section\\s+No\\s+and\\s+Name\\s*[:.]*\\s*(\\d+)\\s*[--]\\s*(.*)', line)\n",
    "        if section_match:\n",
    "            # Extract section number and name for this line\n",
    "            section_number = section_match.group(1).strip()\n",
    "            section_name = section_match.group(2).strip()\n",
    "\n",
    "            # Save section number and name in the assembly_data dictionary\n",
    "            if assembly_constituency_no_and_name not in assembly_data:\n",
    "                assembly_data[assembly_constituency_no_and_name] = {}\n",
    "            assembly_data[assembly_constituency_no_and_name][section_number] = section_name\n",
    "\n",
    "    # Process each line to capture voter IDs, names, relations, age, etc.\n",
    "    for line in lines:\n",
    "        line = line.replace(\"Available\", \"\").replace(\"Photo\", \"\").replace(\":\", \"\").strip()\n",
    "\n",
    "        # Initialize a dictionary for the current entry\n",
    "        current_entry = {}\n",
    "\n",
    "        # Local variables for section_number and section_name\n",
    "        section_number_local = \"\"\n",
    "        section_name_local = \"\"\n",
    "\n",
    "        # Check for ID pattern (3 English characters followed by 7 digits)\n",
    "        id_match = re.match(r'^([A-Z]{3}\\d{7})', line)\n",
    "        if id_match:\n",
    "            id_no = id_match.group(1)\n",
    "\n",
    "            # Check if section_number is already available\n",
    "            if not section_number:\n",
    "                # Use previous line to try and fetch section number and name\n",
    "                prev_number_match = re.search(r'\\d+', previous_line)\n",
    "\n",
    "                # Use prev_number_match to assign section number and name if no section number is available\n",
    "                if prev_number_match:\n",
    "                    section_number_local = prev_number_match.group(0)\n",
    "                    section_name_local = assembly_data.get(assembly_constituency_no_and_name, {}).get(section_number_local, \"Unknown Section Name\")\n",
    "\n",
    "            # If section_number was available, use it; otherwise, use the local fallback\n",
    "            section_number_to_use = section_number if section_number else section_number_local\n",
    "            section_name_to_use = section_name if section_name else section_name_local\n",
    "\n",
    "            # Ensure default values if no match or valid data\n",
    "            section_number_to_use = section_number_to_use or \"Unknown Section No\"\n",
    "            section_name_to_use = section_name_to_use or \"Unknown Section Name\"\n",
    "\n",
    "            # Add the global counter to the current entry\n",
    "            current_entry['No'] = global_counter\n",
    "            global_counter += 1\n",
    "\n",
    "            # Add details to the entry\n",
    "            current_entry['polling station'] = \"126-Sanpada\"\n",
    "            current_entry['ID'] = id_no\n",
    "\n",
    "            # Add the Section Number and Section Name based on extraction\n",
    "            current_entry['Section Number'] = section_number_to_use\n",
    "            current_entry['Section Name'] = section_name_to_use\n",
    "            current_entry['Assembly Constituency No and Name'] = assembly_constituency_no_and_name\n",
    "            current_entry['booth location'] = \"Jerupia English Medium School, Ground Floor, Room No 3, Sector 4, Sanpada, Navi Mumbai, 400705 \"\n",
    "        \n",
    "        # Process patterns for Name, Relation, Age, Gender, etc.\n",
    "        name_match = re.match(r'^Name\\s*[: ]*(.*)', line)\n",
    "        if name_match:\n",
    "            current_entry['Name'] = name_match.group(1).strip()\n",
    "\n",
    "        others_name_match = re.match(r\"^Others\\s*(.*)\", line)\n",
    "        if others_name_match:\n",
    "            current_entry[\"relation name\"] = others_name_match.group(1).strip()\n",
    "            current_entry[\"relation type\"] = \"Other\"\n",
    "\n",
    "        father_name_match = re.match(r\"^Father's Name\\s*(.*)\", line)\n",
    "        if father_name_match:\n",
    "            current_entry[\"relation name\"] = father_name_match.group(1).strip()\n",
    "            current_entry[\"relation type\"] = \"Father\"\n",
    "\n",
    "        mother_name_match = re.match(r\"^Mother's Name\\s*(.*)\", line)\n",
    "        if mother_name_match:\n",
    "            current_entry[\"relation name\"] = mother_name_match.group(1).strip()\n",
    "            current_entry[\"relation type\"] = \"Mother\"\n",
    "\n",
    "        husband_name_match = re.match(r\"^Husband's Name\\s*(.*)\", line)\n",
    "        if husband_name_match:\n",
    "            current_entry[\"relation name\"] = husband_name_match.group(1).strip()\n",
    "            current_entry[\"relation type\"] = \"Husband\"\n",
    "\n",
    "        # Check for Age and Gender\n",
    "        age_gender_match = re.match(r'^Age\\s*(\\d+)\\s*Gender\\s*(\\w+)', line)\n",
    "        if age_gender_match:\n",
    "            current_entry['Age'] = age_gender_match.group(1).strip()\n",
    "            current_entry['Gender'] = age_gender_match.group(2).strip()\n",
    "\n",
    "        # Check for House Number\n",
    "        house_number_match = re.match(r'^House Number\\s*(.*)', line)\n",
    "        if house_number_match:\n",
    "            current_entry['House Number'] = house_number_match.group(1).strip()\n",
    "\n",
    "        # Add the current entry to the results list if it's not empty\n",
    "        if current_entry:\n",
    "            results.append(current_entry)\n",
    "\n",
    "        # Update the previous line after processing the current line\n",
    "        previous_line = line\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize a list to store all results\n",
    "all_results = []\n",
    "\n",
    "# Loop through page numbers (adjust range as needed)\n",
    "for page_number in range(3, 49):\n",
    "    try:\n",
    "        # Construct the image name based on the current loop iteration\n",
    "        image_name = f'page_{page_number}.png'\n",
    "        print(f\"Processing {image_name}...\")\n",
    "\n",
    "        # Textract API call to detect document text\n",
    "        response = client.detect_document_text(\n",
    "            Document={\n",
    "                'S3Object': {\n",
    "                    'Bucket': 'callince',\n",
    "                    'Name': image_name\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Extract text from response\n",
    "        data = \"\\n\".join([x[\"Text\"] for x in response[\"Blocks\"] if x[\"BlockType\"] == \"LINE\"])\n",
    "\n",
    "        # Process the data for this page\n",
    "        page_results = process_text_file(data, page_number)\n",
    "\n",
    "        # Add the processed data to the all_results list\n",
    "        all_results.extend(page_results)\n",
    "\n",
    "    except client.exceptions.ThrottlingException:\n",
    "        print(f\"Rate limit hit while processing page {page_number}. Retrying...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {image_name}: {e}\")\n",
    "\n",
    "# Convert the final results into a dictionary suitable for a DataFrame\n",
    "final_result = {}\n",
    "for entry in all_results:\n",
    "    for key, value in entry.items():\n",
    "        if key not in final_result:\n",
    "            final_result[key] = []\n",
    "        final_result[key].append(value)\n",
    "\n",
    "# Ensure uniform lengths for DataFrame creation\n",
    "max_length = max(len(values) for values in final_result.values())\n",
    "for key in final_result:\n",
    "    final_result[key].extend([None] * (max_length - len(final_result[key])))\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "try:\n",
    "    df = pd.DataFrame.from_dict(final_result)\n",
    "    df.to_csv('126-Sanpada.csv', index=False)\n",
    "    print(\"Data successfully saved to '123 - Sanpada.csv'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while converting to DataFrame or saving to CSV: {e}\")\n",
    "\n",
    "# Output pages with anomalies if any\n",
    "if anomaly_pages:\n",
    "    print(f\"Pages with anomalies: {anomaly_pages}\")\n",
    "else:\n",
    "    print(\"No anomalies detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
